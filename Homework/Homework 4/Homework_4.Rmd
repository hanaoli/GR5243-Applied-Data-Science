---
title: "Homework 4"
author: "Hanao Li, HL3202"
date: ""
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(echo = TRUE, eval = TRUE, comment="", warning = FALSE, message = FALSE, tidy.opts=list(width.cutoff=55), tidy = TRUE)
```


```{r libraries, echo=FALSE}
library(prettydoc)
library(data.table)
library(Hmisc)
library(scales)
library(DT)
library(lubridate)
```

```{r constants, echo=FALSE}
id.name <- "id"
connection.id.name <- "connection_id"
registration.time.name <- "registration.time"

selected.user <- 2000
min.common.connections <- 30

min.connections.q3 <- 250
min.photos.q3 <- 200
min.connection.connections.q3 <- 150

x.per.day <- 5
first.x.days <- 7

x.more <- 100
```

```{r my_functions, echo=FALSE}
round.numerics <- function(x, digits = 0, nearest = 1){
  if(is.numeric(x)){
    return(nearest * round(x = x/nearest, digits = digits))
  }
  else{
    return(x)
  }
}

repair.broken.microseconds <- function(x){
   require(data.table)

   the.pieces <- as.data.table(t(as.data.table(strsplit(x = x, split = ":"))))

   setnames(x = the.pieces, old = names(the.pieces), new = c("date_hours", "minutes", "seconds", "microseconds"))

   the.pieces[microseconds == "00Z", microseconds := "000000Z"]

   the.times <- the.pieces[, sprintf("%s:%s:%s%s", date_hours, minutes, seconds, microseconds)]

   return(the.times)
}
```

```{r read_data_intro, echo=FALSE, eval=TRUE, results='hide'}
toc <- Sys.time()
profiles <- fread(input = "../Data/Profiles.csv")
connections <- fread(input = "../Data/Connections.csv")
registrations <- fread(input = "../Data/Registrations.csv", colClasses = c("character", "POSIXct"), showProgress = FALSE)


registrations[, original.registration.time := get(registration.time.name)]
registrations[, eval(registration.time.name) := ymd_hms(get(registration.time.name))]

w <- which(registrations[, is.na(get(registration.time.name))])

registrations[w, eval(registration.time.name) := ymd_hms(repair.broken.microseconds(x = original.registration.time))]

tic <- Sys.time()

num.lines <- 20
question.counter = 0
```


## About The Data

We will be working with a simulated data set related to social media sites.  The data are stored in several files:

**Profiles.csv**:  Information about the users with some fields from their profiles.

**Connections.csv**:  Information about which users are connected to other users.

**Registrations.csv**: Information about history of the user's account registrations (logins) over time.

**Header** The first row of the data set includes the column names, and each subsequent row includes one observation of values.  Here is a selection of `r num.lines` lines from each data file:

```{r show_header, echo=FALSE, comment=""}
datatable(data = profiles[1:num.lines,])
datatable(data = connections[1:num.lines,])
datatable(data = registrations[1:num.lines,])
```


Here is a brief description of each variable across the three files:

**Profiles Variables**:

- **id**:  A unique identifying string for each user.

- **density**:  The type of area the user lives in, with categories of Urban, Suburban, and Rural areas.

- **gender**:  female (F) or male (M).

- **has_profile_photo**:  1 if yes, 0 if no.

- **num_photos**:  This is the number of photos the user has uploaded to the site.

- **date_created**:  This is the date that the user first joined the site.

**Connections Variables**:

- **id**:  A unique identifying string for each user.

- **connection_id**:  This is the identifier of another user that the user listed under **id** is connected to.

This site chooses to use one-way connections.  A user can connect to a second user's profile without requiring that the second user reciprocally connect to the first one.  So, for any row in the Connections data, the user labeled with **id** is following the user labeled with **connection_id**.  In some cases, pairs of users are mutually following each other, but this is by no means required.  For mutual connections, the users will be coupled in two different rows in the two possible orders.  Each connection for a single user is recorded in a separate row.

**Registrations Variables**:

- **id**:  A unique identifying string for each user.

- **registration.time**:  This is the date and time that a user registered by logging in to the site.  Each registration for a user is recorded in a separate row.


```{r question1, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`:  Classifying Connections

How often do users mutually follow each other, and how often are the connections one-way?  We want to investigate this.  For the investigation, we'll say that a two-way connection requires two one-way connections (two rows of data) but only counts once.  Therefore, the number of overall connections (total one-way plus total two-way) will be less than the overall number of rows of data in the Connections file.  With this in mind, answer these questions.

What percentage of all connections are one-way connections, and what percentage of all connections are two-way connections?

```{r connection_directionality_percentages}
#Reverse datatable and combine
reverse <- connections[, .(id = connection_id, connection_id = id)]
combined.connections <- rbindlist(l = list(connections, reverse))
#Find connections and ids in common
overall.connections <- combined.connections[, .N, by = c(id.name, connection.id.name)]
#Remove unnecessary rows
overall.connections <- overall.connections[1:connections[, .N], ]

#Number of one way connections
overall.connections[N == 1, .N]
#Number of two way connections, For 1 two way connection, only count once here.
overall.connections[N == 2, .N / 2]
#Percentage of one way connections
round(overall.connections[N == 1, .N] / (overall.connections[N == 1, .N] + overall.connections[N == 2, .N / 2]) * 100, 1)
#Percentage of two way connections, Total Connections % = One Way % + Two Way %
round(overall.connections[N == 2, .N / 2] / (overall.connections[N == 1, .N] + overall.connections[N == 2, .N / 2]) * 100, 1)
```
48.8% of all connections are one-way connections, and 51.2% of all connections are two-way connections.

```{r question2, echo=FALSE}
question.counter <- question.counter + 1
```

```{r the_id, echo = FALSE}
the.id <- profiles[selected.user, id]
```


## Question `r question.counter`: Recommending Connections

Which connections should we recommend to the user with id `r the.id`?  One way is to find the unconnected users who are connected to users that user `r the.id` is also connected to.  Create a table of all the users who satisfy all of the following criteria: 
  
* have at least `r min.common.connections` connections in common with user `r the.id`'s connections, and
* are not already connected with user `r the.id`.  
  
The list should show the ids of the recommended users and the number of common connections they have with user `r the.id`.  Order the list in decreasing order of mutual connections.  Make sure not to include `r the.id` on the list of recommendations!


```{r recommendations}
#Selected user's connection and users did not connect to the selected user
user.connected <- connections[id == the.id, ]
user.unconnected <- connections[connection.id.name != the.id, ]

merged <- merge(x = user.connected, y = user.unconnected, by = connection.id.name)
colnames(merged) <- c('connection_id','user: CLKcSSSC','users')
#Filter out users did not meet conditions
recommend.connections <- merged[, .N, by = 'users']
recommend.connections <- recommend.connections[N >= 30 & users != the.id, ]
setorderv(recommend.connections, cols = 'N', order = -1)

datatable(recommend.connections)
```


```{r question3, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`:  Influential Connections

In social networks, some users are considered **influential**.  They tend to have more connections, and their content can be widely viewed and shared.  For our purposes, we will define the **influential users** as those who:

* Have at least `r min.photos.q3` photos, and 
* Have at least `r min.connection.connections.q3` connections.

Among all users (both influential and not so influential), how many users are connected to at least `r min.connections.q3` **influential** users?


```{r characteristics_of_connections}
#Merge Profiles and Connections
profiles_connections <- merge(x = profiles, y = connections, by = id.name)
#Calculate followers
num_followers <- connections[, .(Num_Followers = .N), by = connection.id.name]
setnames(x = num_followers, old = "connection_id", new = "id")
#Filter with photo and number of followers conditions
influential_users <- merge(x = profiles, y = num_followers, by = id.name)
influential_users <- influential_users[num_photos >= 200 & Num_Followers >= 150]
#Users connect to influential users
desired_users <- connections[, get(connection.id.name) %in% influential_users[, get(id.name)]]
#Bind datatable and filter with 250 influential user condition
rbined_dat <- cbind(connections, desired_users)
connected_influential <- rbined_dat[desired_users == "TRUE", ]
connected_influential <- connected_influential[, .N, by = id.name]
connected_influential_250 <- connected_influential[N >= 250, ]
connected_influential_250[, .N]
```




```{r question4, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`: Early Utilizers

Starting from the time when the account for each user was created, what percentage of all users logged in at least `r x.per.day * first.x.days` times during the first `r first.x.days`?  Round your answer to 1 decimal point, e.g. 84.2%.

**Hints**:  Within the **lubridate** library, you can use the function **days** to add a specified number of days to the registration times.  The first week ends before (less than) the user's first registration time plus 7 days.  The registration that occurred when the account was created counts toward the overall total for this period.


```{r regular_users}
#Merge Profile and Registration
profiles_registrations <- merge(x = profiles, y = registrations, by = id.name)
#Find the minimum time and minimum time + 7 
profiles_registrations[, first.registration.time := min(registration.time), by = id.name]
profiles_registrations[, first.7.days := first.registration.time + days(x = 7), by = id.name]
#Filter condition
all_utilizers <- profiles_registrations[registration.time <= first.7.days, .N, by = id.name]
early_utilizers <- all_utilizers[N >= 35, ]
#The answer varies with where you put *100
round(early_utilizers[, .N] / profiles[, .N] * 100, 1)
round(early_utilizers[, .N] * 100 / profiles[, .N], 1)
```



```{r question5, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`: Imbalanced Connections

What percentage of users have at least `r x.more` more followers than the number of users that they are following?  Round the answer to 1 decimal place, e.g. 84.2%.

```{r imbalanced_connection_percentage}
#Find connections and followers
num_following <- connections[, .(Num_Following = .N), by = id.name]
num_followers <- connections[, .(Num_Followers = .N), by = connection.id.name]
setnames(x = num_followers, old = "connection_id", new = "id")
#Merge tables
connections_counts <- merge(x = num_following, y = num_followers, by = id.name)
#Calculate imbalanced connections
imbalanced_connections <- connections_counts[, .(Followers_Minus_Following = Num_Followers - Num_Following), by = id.name]
imbalanced_connections_100 <- imbalanced_connections[Followers_Minus_Following >= 100, ]

round(imbalanced_connections_100[, .N] /  profiles[, .N] * 100, 1)
```





```{r question6, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`:  Active Users

What percentage of unique users in the sample were active (with at least 1 registration) between 00:00:00 of January 1st, 2017 and 23:59:59 on January 7th, 2017?  Round the percentage to 1 decimal place, e.g. 84.2%

**Hint**:  For any given date in character format (e.g. "1999-07-01"), you can calculate a date in the future with the **as.Date** function:  as.Date("1999-07-01") + 3 would result in "1999-07-04".

```{r active_users}
#Find active users
active_users <- profiles_registrations[registration.time >= as.Date("2017-01-01 00:00:00") & registration.time <= as.Date("2017-01-07 23:59:59"), ]

active_user_list <- active_users[, .N, by = id.name]
round(active_user_list[, .N] /  profiles[, .N] * 100, 1)
```


```{r question7, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`:  Burning the Midnight Oil

Across all days, what percentage of all registrations occur between the hours of 00:00:00 and 05:59:59, inclusive of both endpoints?  Round your answer to 1 decimal place, e.g. 84.2%.  **Hint:**  Use the hour() function to classify the time of day.


```{r midnight_oil}
# all.registrations <- hour(profiles.plus.registrations$first.registration.time)
midnight_registrations <- profiles_registrations[hour(registration.time) >= 0 & hour(registration.time) < 6, ]

round(midnight_registrations[, .N] / profiles_registrations[, .N] * 100, 1)
```



```{r question8, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`:  Retention Rates

What percentage of users were retained at 183 days (half a year)?  To answer this question, we will use a 7 day window.  Any user who had at least one registration in the period of time that was at least 183 days and less than 190 days from their first registration would be considered retained.  Round your answer to 1 decimal place, e.g. 84.2%.

**Note:** The evaluation window would begin at exactly 183 days after the first registration.  This period lasts for 7 days.  This window would include the left end-point but not the right end-point.  The registration times are listed in the data set rounded to the nearest second. If the user had at least 1 registration during this window, the user would be considered retained at 183 days (approximately 6 months).

**Hint:**  You may use the **days()** function to add time to a user's initial registration time.


```{r retention_rate}
#Calculate retention period
retention_dat <- merge(x = profiles, y = registrations, by = id.name)
retention_dat[, first_registration_time := min(registration.time), by = id.name]
retention_dat[, starting_period := first_registration_time + days(x = 183), by = id.name]
retention_dat[, ending_period := first_registration_time + days(x = 190), by = id.name]
#Filter out users
retained_users <- retention_dat[registration.time >= starting_period & registration.time < ending_period, .N, by = id.name]

round(retained_users[, .N]/ profiles[, .N] * 100, 1)
```

```{r question9, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`:  False Positive Rates

In the previous question, we estimated the rate of retention at 6 months using a 7-day window for evaluation.  What is the rate of false positives for the 7-day window?  In other words, what percentage of users who were considered not retained at 6 months using a 7-day window later had a registration?  Round the results to 2 decimal places, e.g. 84.23%.

```{r false_positive_rate}
#User ID considered retained
users_retained <- retention_dat[, get(id.name) %in% retained_users[, get(id.name)]]
#Users who were not considered retained but had a late registration
retention_rbined <- cbind(retention_dat, users_retained)
false_positive_users <- retention_rbined[users_retained == "FALSE" & registration.time > ending_period, .N, by = id.name]

round(false_positive_users[, .N] / (profiles[, .N] - retained_users[, .N]) * 100, 2)
```



```{r question10, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`:  Modeling Retention

Build a logistic regression model for retention at 6 months.  Classify users as retained at 6 months if they have any account registrations at times at least 183 days after their account was created.  Include the following variables:
  
* density
* age_group
* gender
* num_photos (categories:  0-24, 25-49, 50-99, 100-249, 250-499, 500+)  (current status)
* average daily registrations in the first week.  (To simplify matters, let this be the total number of registrations in the first week divided by 7, regardless of whether the user's retention truly lasted 7 days or not.)
* number of connections the user currently has
* number of users currently connected to this user

Display the odds ratios, confidence intervals for the odds ratios, and p-values for the coefficients, rounded to 3 digits.  Then briefly comment on the results.

```{r retention_model}
#Add retained variable
retained_users10 <- retention_dat[registration.time >= starting_period, .N, by = id.name]
model_dat <- profiles[, Retained := get(id.name) %in% retained_users10[, get(id.name)]]
#Cut number of photos
cuts.photo <-c(25, 50, 100, 250, 500, 1500)
model_dat[, Num_photos := cut2(x = num_photos, cuts = cuts.photo)]
#Add number of followers
model_dat <- merge(x = model_dat, y = num_followers, by = id.name)
#Add number of connections
model_dat <- merge(x = model_dat, y = num_following, by = id.name)
#Remove unnecessary columns
model_dat[, c("has_profile_photo", "num_photos", "date_created") := NULL]
#Add average daily registration
model_date <- registrations
model_date[, first_regis := min(registration.time), by = id.name]
model_date[, first_week := min(registration.time) + days(x = 7), by = id.name]
average_date <- model_date[registration.time >= first_regis & registration.time <= first_week, .(Average_Registration = .N / 7), by = id.name]
model_dat <- merge(x = model_dat, y = average_date, by = id.name)
#Correct str
model_dat$density <- as.factor(model_dat$density)
model_dat$age_group <- as.factor(model_dat$age_group)
model_dat$gender <- as.factor(model_dat$gender)
#Model
glm_mod <- glm(Retained ~ ., family = binomial, data = model_dat[, -1])
result <- round(cbind(exp(cbind(coef(glm_mod), confint(glm_mod))), coef(summary(glm_mod))[, 4]), 3)
colnames(result) <- c("Odds Ratio", "2.5%", "97.5%", "P-value")
datatable(result)
```

From the results, we could see that density variables, age group of 45-54 and age group of 55-64,
genderm, number of following are and average registrations are very significant while all the photo vaariables did little contribution to the data. Average registration has the highest odds ratio among other variables.

